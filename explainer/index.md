# Explainer: LLM Markup (LLMPM)

## Status

This document is the non-normative explainer for the LLM Markup specification. For the formal standard, see [spec/index.bs](../spec/index.bs).

## Problem Statement

As LLMs become integrated into web browsers and user agents, there is no standardized way for content authors to:

1. **Control visibility**: Specify what content an LLM can "see" in its context window
2. **Control mutations**: Define what changes an LLM is permitted to make
3. **Control retention**: Declare data privacy and storage rules
4. **Provide semantics**: Guide how content should be interpreted
5. **Track provenance**: Maintain accountability for AI-generated modifications

Without such standards, LLM-infused browsers face a dilemma:
- **Too permissive**: LLMs might expose sensitive data or make unauthorized changes
- **Too restrictive**: LLMs cannot provide useful assistance with web content
- **Inconsistent**: Different implementations handle the same content differently

## Solution: A Declarative Contract

LLM Markup provides a declarative contract layer that sits on top of existing HTML. It uses three orthogonal namespaces to address different concerns:

### 1. LLM-Policy (Access & Permissions)

Policy attributes define the **hard boundaries** of the interaction. The User Agent enforces these by **redacting content** from the context window (Input Policy) and ensuring the LLM is **never prompted to mutate** restricted sections (Output Policy). Immutable content passes through the interaction layer unaltered, with the UA acting as a mechanistic barrier to unauthorized changes.

```html
<!-- Visibility Control -->
<div llm-policy-input="none">         <!-- Hidden entirely -->
<div llm-policy-input="structure">    <!-- Tags visible, text redacted -->
<div llm-policy-input="structure text"> <!-- Tags and text, no custom attributes -->
<div llm-policy-input="all">          <!-- Everything visible (default) -->

<!-- Mutation Control -->
<div llm-policy-output="readonly">    <!-- No changes allowed (default) -->
<div llm-policy-output="style">       <!-- Can change class/style only -->
<div llm-policy-output="annotation">  <!-- Can wrap text, not change it -->
<div llm-policy-output="content">     <!-- Can edit text content -->
<div llm-policy-output="mutable">     <!-- Full modification allowed -->

<!-- Retention Control -->
<div llm-policy-memory="none">        <!-- Ephemeral only (default) -->
<div llm-policy-memory="session">     <!-- Session-scoped retention -->
<div llm-policy-memory="user">        <!-- User profile storage -->
<div llm-policy-memory="training">    <!-- Training data authorized -->
```

### 2. LLM-Intent (Prompt Construction)

Intent attributes govern the **deterministic construction of prompts**. The User Agent translates these semantic markers into the framing and instructions seen by the LLM. While mechanistic in its generation, the Intent namespace controls the *context and direction* of the model without redacting content or directly enforcing mutation permissions.

```html
<!-- Semantic Categories -->
<div llm-intent-category="summary">       <!-- Condensed content -->
<div llm-intent-category="legal-disclaimer"> <!-- Do not paraphrase -->
<div llm-intent-category="code-block">    <!-- Preserve formatting -->
<div llm-intent-category="satire">        <!-- Do not interpret literally -->

<!-- Importance Levels -->
<div llm-intent-importance="critical">    <!-- Must preserve if truncating -->
<div llm-intent-importance="background">  <!-- Ignore unless asked -->

<!-- Entity References -->
<span llm-intent-entity="https://wikidata.org/wiki/Q5">Albert Einstein</span>

<!-- Custom Instructions -->
<div llm-intent-instruction="Translate to plain English">
```

### 3. LLM-Provenance (Audit Trail)

Provenance attributes serve as a **dynamic ledger** for the content. They track not only the original source of information but also **record every mutation applied by the LLM**. When an LLM modifies content (e.g., summarizing text, highlighting warnings), the User Agent automatically appends these operations to the provenance history, ensuring full accountability for AI-generated changes.

```html
<!-- Source Attribution -->
<p llm-provenance-source="https://example.com/article"
   llm-provenance-citation="Smith, 2024">

<!-- Confidence Levels -->
<p llm-provenance-confidence="0.95">High-confidence fact</p>
<p llm-provenance-confidence="0.3">Speculative interpretation</p>

<!-- Modification History (Auto-generated by UA) -->
<p llm-provenance-operation="content:summarized style:highlighted">
```

#### Multi-hop & Nested Provenance

The standard handles "chains of custody" (e.g., a summary of a summary) through **node-scoped attribution**:

- **Node Isolation**: Provenance attributes are local to the node they describe. If an LLM-generated summary is embedded within another document, it retains its own `llm-provenance-*` attributes.
- **The Source Chain**: The `llm-provenance-source` attribute links back to the immediate upstream authority. In a multi-hop scenario (Browser -> Gemini -> Original Site), the Gemini-generated fragment points to the Original Site, while the Browser-level summary points to the Gemini-generated URI.
- **Cumulative Operations**: The `llm-provenance-operation` attribute is a space-separated list. As content moves through multiple LLM "hops," each agent appends its rationale to the existing ledger, creating a persistent audit trail.

#### Integrity & Persistence

To ensure trust, the User Agent enforces strict integrity rules on provenance data:

1.  **Baseline Trust**: Provenance tags served with the initial document are treated as the "original state." The User Agent trusts these as the starting point of the ledger.
2.  **Append-Only History**: The User Agent ensures that new operations are **appended** to the history, never overwriting or deleting existing entries.
3.  **Tamper Protection**: The User Agent maintains an internal, parallel ledger of all LLM-initiated changes. If a page script attempts to modify or delete `llm-provenance` attributes to hide AI involvement, the User Agent detects the mismatch and **restores the correct attributes**, ensuring the audit trail remains immutable for the duration of the session.

## Key Design Principles

### 1. User Agent as Authority

The conforming entity is the **User Agent (browser)**, not the LLM. This is crucial because:

- LLMs are probabilistic and may not follow instructions reliably
- Security cannot depend on LLM compliance
- Deterministic enforcement is auditable and testable

The UA intercepts all LLM interactions and enforces policies mechanistically.

### 2. Secure Defaults

- **Input**: `all` (visible by default, authors opt-out)
- **Output**: `readonly` (immutable by default, authors opt-in to mutations)
- **Memory**: `none` (ephemeral by default, authors opt-in to retention)

This follows the principle of least privilege for mutations and data retention.

### 3. Intersection Semantics

When multiple policies apply (inheritance, Shadow DOM, licenses), the effective policy is the **intersection** of all applicable constraints. Both parties must agree for a permission to be granted.

### 4. Graceful Degradation

LLM Markup attributes are ignored by browsers that don't support them. Content remains functional and accessible without LLM features.

## Global Policy

In addition to element-level attributes, authors can define document-wide policies via HTTP headers or meta tags:

```http
LLM-Policy: {
  "defaults": {
    "llm-policy-input": ["structure", "text"],
    "llm-policy-output": ["readonly"],
    "llm-policy-memory": ["none"]
  },
  "constraints": {
    "block-selectors": [".pii", "[data-sensitive]"],
    "category-rules": {
      "advertisement": {"llm-policy-input": ["none"]}
    }
  },
  "report-to": "https://api.example.com/llm-reports"
}
```

**Precedence**: HTTP Header > Meta Tag > Element Attributes > Defaults

### Precedence Logic

The Global Policy supports two distinct mechanisms with different precedence rules:

1.  **Constraints (Intersection Semantics):** Rules defined in `constraints` (e.g., `block-selectors`, `category-rules`) form a hard ceiling. They **cannot be overridden** by local attributes. The effective policy is the intersection of the constraint and the local attribute.
    *   *Example:* If a global constraint blocks PII, a local `llm-policy-input="all"` attribute is ignored.

2.  **Defaults (Override Semantics):** Rules defined in `defaults` act as fallbacks for elements without explicit attributes. They **can be overridden** by local attributes.
    *   *Example:* If the global default is `readonly`, a local `llm-policy-output="mutable"` attribute takes precedence.

**Hierarchy:** Global Constraints > Local Attributes > Global Defaults > Specification Defaults.

## Shadow DOM Boundaries

Web components with Shadow DOM create **policy boundaries**:

- By default, policies do NOT cross shadow boundaries (opt-out)
- Component authors can opt-in to inheritance
- Intersection semantics ensure mutual agreement
- Component authors have precedence within their shadow trees

```javascript
this.attachShadow({
  mode: 'open',
  llmPolicyInherit: true,  // Opt-in to page policies
  llmProvenanceTransparent: true  // Report full provenance to document
});
```

## License Enforcement

Content licenses are enforced via the License Compatibility Matrix:

```html
<!-- CC-BY-ND restricts to readonly + annotation -->
<article llm-policy-license="CC-BY-ND-4.0">
  <!-- Even with llm-policy-output="mutable", effective is readonly -->
</article>
```

Supported licenses include Creative Commons family, open source licenses (MIT, Apache, GPL), and proprietary markers.

## Use Cases

See the [use-cases/](./use-cases/) directory for detailed scenarios:

- **News Article**: Protecting quotes, allowing summaries
- **E-commerce**: Product data editable, prices readonly
- **Legal Document**: Highlighting allowed, text immutable
- **Educational**: Interactive examples, explanations appendable
- **Medical**: Strict readonly for safety-critical information
- **User-Generated Content**: Moderation policies

## Relationship to Other Standards

| Standard | Relationship |
|----------|--------------|
| ARIA | Complementary - ARIA for accessibility, LLMPM for AI |
| CSP | Orthogonal - CSP for script security, LLMPM for AI permissions |
| robots.txt | Different scope - robots.txt for crawlers, LLMPM for in-page AI |
| RDFa/JSON-LD | Complementary - structured data + AI policies |

## FAQ

**Q: Does this give LLMs permission to scrape my content?**

A: No. LLM Markup governs how an LLM-infused UA interacts with content the user is already viewing. It does not affect crawling or training data collection, which are separate concerns.

**Q: What if the LLM ignores the policies?**

A: The LLM cannot ignore policies because the User Agent enforces them before the LLM sees the content. The LLM only receives pre-filtered context.

**Q: Can malicious content use this to attack the LLM?**

A: Policies are parsed deterministically by the UA, not interpreted by the LLM. The LLM never sees policy attributes, only filtered content.

**Q: Is this backward compatible?**

A: Yes. Browsers that don't support LLM Markup ignore the attributes. Content remains functional.

## Next Steps

1. Review the [formal specification](../spec/index.bs)
2. Explore the [examples](../examples/)
3. Run the [conformance tests](../tests/web-platform-tests/)
4. Review the [Security & Privacy questionnaire](./security-privacy.md)
