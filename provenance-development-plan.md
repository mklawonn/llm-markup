# Provenance Namespace Development Plan

The goal of the `llm-provenance` namespace is to enable **Trust, Accountability, and Auditability** for content consumed or generated by LLMs.

Unlike `llm-policy` (Publisher Constraints) or `llm-intent` (Semantic Meaning), `llm-provenance` functions as an **Internal Ledger** or **Interchange Format** for the User Agent. It tracks the origin and reliability of information as it is synthesized from multiple sources (e.g., current page, external search, internal knowledge) into a final response.

This plan outlines the development of the alpha version of the Provenance Namespace, focusing on the **Agent-Centric / Synthesis Model**.

## Phase 1: Source Tracking (The "Where")
*Focus: Identifying the origin of information chunks.*

1.  **Introduce `llm-provenance-source` (Origin Layer):**
    *   **Goal:** Track the canonical source URI of a content block.
    *   **Value:** URI (e.g., `https://techradar.com`, `urn:internal:knowledge-base`).
    *   **Use Case:** Enabling citations and source-linking in the final UI.

2.  **Introduce `llm-provenance-citation` (Presentation Layer):**
    *   **Goal:** Provide a human-readable label for the source.
    *   **Value:** String (e.g., "[1]", "TechRadar", "User Knowledge").
    *   **Use Case:** Rendering citation badges next to generated text.

## Phase 2: Synthesis Roles (The "How")
*Focus: Defining how information is used in the synthesis.*

1.  **Introduce `llm-provenance-role` (Semantic Layer):**
    *   **Goal:** Define the function of a content block within the synthesized response.
    *   **Proposed Taxonomy:**
        *   `primary`: The main subject matter (e.g., the current page content).
        *   `secondary`: Supporting evidence from external sources.
        *   `context`: Background information or definitions.
        *   `correction`: Agent-generated corrections or warnings (e.g., fact-checks).
    *   **Use Case:** UI highlighting (e.g., blue for primary, green for secondary, yellow for corrections).

## Phase 3: Reliability & Process (The "Trust" & "How")
*Focus: Communicating uncertainty and transformation history.*

1.  **Introduce `llm-provenance-confidence` (Data Layer):**
    *   **Goal:** Express the agent's certainty in the accuracy of a specific chunk.
    *   **Value:** Float (0.0 - 1.0).
    *   **Use Case:** Graying out or flagging low-confidence information.

2.  **Introduce `llm-provenance-operation` (Process Layer):**
    *   **Goal:** Track the transformation applied to the source content.
    *   **Proposed Taxonomy:**
        *   **Content:** `summary`, `translation`, `verbatim`, `synthesis`.
        *   **Presentation:** `restyle` (Style changes only).
        *   **Structure:** `refactor` (Code/Logic), `reorder` (List permutation).
        *   **Interaction:** `adaptation` (Adding interactive behaviors).
        *   **Semantic:** `intent-match` (Classifying content based on user query/intent).
    *   **Use Case:** User asks "Summarize this". Output is tagged `operation="summary"`. User asks "Find warnings". Output is tagged `operation="intent-match"`.

## Processing Model & Conformance (The "Rules")

To ensure trust, the User Agent (UA) acts as the **Authority** on provenance, enforcing labeling independently of the LLM's text generation.

### 1. Deterministic Labeling
The User Agent MUST wrap content in provenance containers based on the retrieval method and operation performed.
*   **External Data:** If the UA fetches data from an external source (e.g., search result), it MUST wrap that content in a container with `llm-provenance-source` and `llm-provenance-role="secondary"` *before* rendering.
*   **Operation Tracking:** When the UA delegates a task to the LLM (e.g., summarization), it MUST tag the output container with the corresponding `llm-provenance-operation` (e.g., `summary`).
*   **LLM Confidence:** The UA MAY query the LLM for a confidence score, but the UA MUST parse and apply the `llm-provenance-confidence` attribute to the container itself. The LLM provides the signal; the UA applies the label.

### 2. Rendering Requirements (Conspicuous Disclosure)
Provenance metadata MUST be accessible to the user.

*   **Mandatory Inspection:** The User Agent MUST provide a mechanism for the user to inspect the raw provenance data (Source, Role, Operation, Confidence) for any element. This MAY be implemented as a context menu item (e.g., "Inspect Provenance"), a dedicated panel, or a developer tool interface similar to "View Source".
*   **Recommended Practices:** To ensure conspicuous disclosure, the User Agent SHOULD visually distinguish content based on its `llm-provenance-role`.
    *   *Examples:* Colored borders for secondary sources, background highlights for corrections, or icons for AI-generated content.
    *   *Goal:* Users should be able to intuitively distinguish between primary content and synthesized/external content without needing to inspect every element.
*   **Non-Compliance:** Completely hiding provenance data with no way to access it is non-compliant.
